<!DOCTYPE html>
<html lang="en">
  <head>
    <link rel="stylesheet" href="/static/stylesheet.css" />
    <meta charset="UTF-8" />
    <title>Questions · Benjamin Stubbing</title>
  </head>
  <body>
    <div id="menu">
      <span class="title">Benjamin Stubbing</span>
      <ul>
        <li><a href="/menu/about.html">About</a></li>
        <li><a href="/menu/essays.html">Essays</a></li>
        <li><a href="/menu/diningguide.html">Wellington Dining Guide</a></li>
        <li><a href="/menu/pina-colada.html">Piña Colada Town</a></li>
        <li><a href="/menu/people&links.html">People & Links</a></li>
        <li><a href="/menu/bookshelf.html">Bookshelf</a></li>
        <li><a href="/menu/questions.html">Questions</a></li>
      </ul>
    </div>
    <div id="left">&nbsp;</div>
    <div id="content">
      <p>The open tabs of my mind and questions that I find interesting.</p>
      <ul>
        <li>Why can't we see the effects of computers in the longitudinal productivity statistics?</li>
        <li>What are the costs of focusing on reducing emmisisons instead of productivity growth?</li?>
        <li>Does debt-financed disaster relief come at the expense of future growth? </li>
        <li>Research about interventions in bias: can we improve people's judgement in some lasting way that impacts decisions that they make for their life or career</li>
        <li>How well does good forecasting ability transfer across domains? </li>
        <li>What’s the best way to measure individual wellbeing (on different assumptions)? (Adapted from Happier Lives Institute, Research agenda) </li>
        <li>What are the best methodologies for evaluating policy options for unprecedented future scenarios? (Inspired by Max Stauffer et al., Research Directions on Improving Policy-making) </li>
        <li>What regulatory and other government approaches can prevent AI technologies from being misused? For example, how — if at all — could compliance with a treaty agreeing to restrictions on the development of lethal autonomous weapons be reliably verified? (Adapted from CNAS, Artificial Intelligence and Global Security Initiative Research Agenda) </li>
        <li>Toby Ord has argued that because the human species has survived for a long time, we can conclude the natural per-century human existential risk is low (or else it’d be extremely unlikely that we’d be here). Does this argument still hold if we assume there are millions of potentially intelligent species evolving throughout the history of the universe, and only those that survive about as long as we have become advanced enough to ask questions about how high natural extinction risk is? </li>
        <li>Assuming we are uncertain about what moral theory to believe, is there anything wrong with some views with very high stakes dominating our uncertainty-adjusted moral conclusions (‘fanaticism’)? For example, if you think theory A is very unlikely to be true, but it says action X is extremely valuable, while all other theories think X is just slightly bad, is there anything wrong with concluding you should do X? If so, what plausible view of moral uncertainty would allow us to avoid this conclusion? (Adapted from Global Priorities research agenda) </li>
        <li>What concerns are there with representing people as having utility functions? What alternatives are there</li>
        <li>Although it has been frequently argued that advanced AI goals should reﬂect ‘human values’, which particular values should be preserved (given that there is a broad spectrum of inconsistent views across the globe and across time about what these values should be)? (Adapted from Future of Life Institute, A survey of research questions for robust and beneﬁcial AI) </li>
        <li>What are the best heuristics for reliably identifying experts on a topic, or choosing what to believe when apparent experts disagree? </li>
        <li>How can we distinguish between AIs helping us better understand what we want and AIs changing what we want (both as individuals and as a civilisation)? How easy is the latter to do; and how easy is it for us to identify? (Richard Ngo, Technical AGI safety research outside AI) </li>
        <li>How feasible is an eventual rise of a global and potentially long-lasting totalitarian regime? What are potential predictors of such a regime? (Such as, perhaps, improved surveillance technologies or genetic engineering?) (Adapted from Michael Aird, Crucial questions for longtermists) </li>
        <li>How could AI transform domestic and mass politics? E.g. will AI-enabled surveillance, persuasion, and robotics make totalitarian systems more capable and resilient? (Allan Dafoe, AI Governance: A Research Agenda) </li>
        <li>How will geopolitical, bureaucratic, cultural, or other factors affect how actors choose to adopt AI technology for military or security purposes? (CNAS, Artificial Intelligence and Global Security Initiative Research Agenda) </li>
        <li>Will AI come to be seen as the one of the most strategically important parts of the modern economy, warranting massive state support and intervention? If so, what policies might this cause countries to adopt, and how will this AI nationalism interact with global free trade institutions and commitments? (Adapted from Allan Dafoe, AI Governance: A Research Agenda) </li>
        <li>What are the conditions that could spark and fuel an international AI race? How great are the dangers from such a race, how can those dangers be communicated and understood, and what factors could reduce or exacerbate them? What routes exist for avoiding or escaping the race, such as norms, agreements, or institutions regarding standards, verification, enforcement, or international control? (Allan Dafoe, AI Governance: A Research Agenda) </li>
        <li>What’s the best way to measure individual wellbeing? What’s the best way to measure aggregate wellbeing for groups? </li>
        <li>What can economic models — especially models of economic growth — tell us about recursive self improvement in advanced AI systems? (Adapted from AI Impacts, Promising research projects) </li>
        <li>Can concerns about unaligned artificial intelligence or economic dominance by influence-seeking agents be reformulated in terms of standard economic ideas, such as principal-agent problems and the effects of automation? (Adapted from Richard Ngo, Technical AI Safety research outside AI) </li>
        <li>Of the comprehensive macroeconomic indices already available to us, which serve best as proxies for long-term expected global welfare (including but not limited to considerations of existential risks)? What would be the broad policy implications of targeting such indices instead of GDP per capita? (Global Priorities Institute, Research Agenda) </li>
        <li>What is the optimal design of international institutions that are formed to increase global public goods or decrease global public bads? (Global Priorities Institute, Research Agenda)
        <li>To combat climate change, and the precariousness of last-minute supply chains, do we need to produce more of our own food and import less? </li>
        <li>Characterize the remaining uncertainties around nuclear war then use Monte Carlo techniques to show the distribution of outcome possibilities, with a special focus on the worst-case possibilities compatible with our current understanding. </li>
        <li>Why is CS-GO not popular in Asia? Is there a norm against violent games in Asia? Is this a good thing? </li>
        <li>If every team at pro-level defaults to the best meta, isn't the optimum now to undermine this strategy? </li>
        <li>Is the US dollar vulnerable? </li>
        <li>To what extent is the robustness of Democracy in NZ due to culture? </li>
        <li>Should natural monopolies be run by the government? </li>
        <li>Why does construction on public works take so long in NZ? </li>
        <li>How will breakthroughs in AI, Biotech, and energy change international politics? </li>
        <li>How can we mitigate the threat of Chinese authoritarianism, while preparing for a China-centric world order?</li>
        <li>How could NZ position itself as an agriculture-biotech powerhouse? </li>
        <li>Should NZ be trying to turn agriculture green or should we be trying to sunset agriculture and replace it with clean meat? </li>
        <li>If NZ's primary energy sources were fully renewable, could we become a net exporter of energy? </li>
        <li>What should NZ education look like? Should university be free? Should we have retraining programs for the future of work (as in Germany)? Should high school look more like Singapore? Could we position ourselves as an education powerhouse like University of California. How can we attract more talented faculty? (grant money, quality of life, quality of collaborators) </li>
        <li>Should we rejoin NZ universities to recreate the University of NZ? </li>
        <li>Should we adopt a state housing initiative like Singapore's? </li>
        <li>Should we regulate housing construction aesthetics in central cities to enhance quality of life? </li>
        <li>Do we need rural towns? </li>
        <li>How can we meet our workforce needs in horticulture? </li>
        <li>Are we worse off than our parents? </li>
        <li>What would a constitutional arrangement with Tino Rangatiratanga look like? </li>
        <li>How can NZ make money from its film industry? </li>
        <li>How do we integrate the claims of nature with the claims of progress? </li>
        <li>Why has there not been a decline in working hours? </li>
        <li>Are more developed (liberal democracies) economies more commensurate to meritocracy? </li>        
      </ul>
    </div>
  </body>
</html>
